{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQxvrjHwRZLz",
        "outputId": "ece54e9f-8978-4a62-b6d9-ef9b9b6ccf0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokens in the sentence:  ['Oh', 'man', ',', 'this', 'is', 'pretty', 'cool', '.', 'We', 'will', 'do', 'more', 'such', 'things', '.']\n",
            "\n",
            "Tokens without stop words:  ['Oh', 'man', ',', 'pretty', 'cool', '.', 'We', 'things', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Stop words removal #\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Jul 17 14:52:37 2021\n",
        "\n",
        "@author: Niveditha\n",
        "\"\"\"\n",
        "\n",
        "# Importing NLTK library and stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Downloading required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Random sentence with a lot of stop words\n",
        "sample_text = \"Oh man, this is pretty cool. We will do more such things.\"\n",
        "\n",
        "# Tokenizing the text\n",
        "text_tokens = word_tokenize(sample_text)\n",
        "\n",
        "# Removing stopwords\n",
        "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
        "\n",
        "# Printing the original tokens and the tokens without stopwords\n",
        "print(\"\\nTokens in the sentence: \",text_tokens)\n",
        "print(\"\\nTokens without stop words: \",tokens_without_sw)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import webtext\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "# Loading data - text file\n",
        "words = [w.lower() for w in webtext.words(\n",
        "    'F:\\\\ODD 2021 - 2022\\\\NLP\\\\Hands-on\\\\Short_story.txt')]\n",
        "\n",
        "stopset = set(stopwords.words('english'))\n",
        "filter_stops = lambda w: len(w) < 3 or w in stopset\n",
        "\n",
        "trigram_collocation = TrigramCollocationFinder.from_words(words)\n",
        "trigram_list = trigram_collocation.nbest(TrigramAssocMeasures.likelihood_ratio, 20)\n",
        "for t in trigram_list:\n",
        "    print(t)\n",
        "\n",
        "print(\"\\n\\nAfter stop word removal\\n\")\n",
        "trigram_collocation.apply_word_filter(filter_stops)\n",
        "trigram_list = trigram_collocation.nbest(TrigramAssocMeasures.likelihood_ratio, 20)\n",
        "for t in trigram_list:\n",
        "    print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "g_Xl4naiUrMW",
        "outputId": "77845640-9923-40a9-8e81-1259a5720bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No such file or directory: \"/root/nltk_data/corpora/webtext/Once upon a twinkling star, a purple elephant danced joyously. Beneath the waffle tree, unicorns hummed a melody, attracting jellybean birds. A wizard with a marshmallow hat cast spells to make clouds rain lemonade. Nearby, a dragon knitted socks while giggling at a squirrel wearing sunglasses. In this magical land, every Tuesday was backwards, and frogs recited poetry. Suddenly, a rainbow-colored cat exclaimed, 'To the moon, my friends!' and everyone cheered. Together, they floated on a giant soap bubble, leaving a trail of sparkling confetti behind, spreading laughter and whimsical dreams to every corner of the enchanted forest.\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3f63d7f7c053>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Loading data - text file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwebtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Once upon a twinkling star, a purple elephant danced joyously. Beneath the waffle tree, unicorns hummed a melody, attracting jellybean birds. A wizard with a marshmallow hat cast spells to make clouds rain lemonade. Nearby, a dragon knitted socks while giggling at a squirrel wearing sunglasses. In this magical land, every Tuesday was backwards, and frogs recited poetry. Suddenly, a rainbow-colored cat exclaimed, 'To the moon, my friends!' and everyone cheered. Together, they floated on a giant soap bubble, leaving a trail of sparkling confetti behind, spreading laughter and whimsical dreams to every corner of the enchanted forest.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mstopset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/plaintext.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m     74\u001b[0m             [\n\u001b[1;32m     75\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCorpusView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_word_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspaths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             ]\n\u001b[1;32m     78\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36mabspaths\u001b[0;34m(self, fileids, include_encoding, include_fileid)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclude_encoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minclude_fileid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclude_encoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minclude_fileid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, fileid)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, _path)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file or directory: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No such file or directory: \"/root/nltk_data/corpora/webtext/Once upon a twinkling star, a purple elephant danced joyously. Beneath the waffle tree, unicorns hummed a melody, attracting jellybean birds. A wizard with a marshmallow hat cast spells to make clouds rain lemonade. Nearby, a dragon knitted socks while giggling at a squirrel wearing sunglasses. In this magical land, every Tuesday was backwards, and frogs recited poetry. Suddenly, a rainbow-colored cat exclaimed, 'To the moon, my friends!' and everyone cheered. Together, they floated on a giant soap bubble, leaving a trail of sparkling confetti behind, spreading laughter and whimsical dreams to every corner of the enchanted forest.\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TRIGRAM\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "# Function to read text from a file\n",
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Loading data - text file\n",
        "file_path = '/content/NLP_trigram_example_shakespeare_excerpt.txt'\n",
        "words = read_text_file(file_path).lower().split()\n",
        "\n",
        "stopset = set(stopwords.words('english'))\n",
        "filter_stops = lambda w: len(w) < 3 or w in stopset\n",
        "\n",
        "trigram_collocation = TrigramCollocationFinder.from_words(words)\n",
        "trigram_list = trigram_collocation.nbest(TrigramAssocMeasures.likelihood_ratio, 20)\n",
        "for t in trigram_list:\n",
        "    print(t)\n",
        "\n",
        "print(\"\\n\\nAfter stop word removal\\n\")\n",
        "trigram_collocation.apply_word_filter(filter_stops)\n",
        "trigram_list = trigram_collocation.nbest(TrigramAssocMeasures.likelihood_ratio, 20)\n",
        "for t in trigram_list:\n",
        "    print(t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed34ec5-46c6-4a92-ca6e-b8a673c73206",
        "id": "1YHTcIJya5vt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('attracting', 'jellybean', 'birds.')\n",
            "('behind,', 'spreading', 'laughter')\n",
            "('cat', 'exclaimed,', '\"to')\n",
            "('cheered.', 'together,', 'they')\n",
            "('clouds', 'rain', 'lemonade.')\n",
            "('confetti', 'behind,', 'spreading')\n",
            "('danced', 'joyously.', 'beneath')\n",
            "('dragon', 'knitted', 'socks')\n",
            "('elephant', 'danced', 'joyously.')\n",
            "('everyone', 'cheered.', 'together,')\n",
            "('frogs', 'recited', 'poetry.')\n",
            "('giant', 'soap', 'bubble,')\n",
            "('hat', 'cast', 'spells')\n",
            "('in', 'this', 'magical')\n",
            "('knitted', 'socks', 'while')\n",
            "('make', 'clouds', 'rain')\n",
            "('marshmallow', 'hat', 'cast')\n",
            "('melody,', 'attracting', 'jellybean')\n",
            "('moon,', 'my', 'friends!\"')\n",
            "('purple', 'elephant', 'danced')\n",
            "\n",
            "\n",
            "After stop word removal\n",
            "\n",
            "('attracting', 'jellybean', 'birds.')\n",
            "('behind,', 'spreading', 'laughter')\n",
            "('cat', 'exclaimed,', '\"to')\n",
            "('clouds', 'rain', 'lemonade.')\n",
            "('confetti', 'behind,', 'spreading')\n",
            "('danced', 'joyously.', 'beneath')\n",
            "('dragon', 'knitted', 'socks')\n",
            "('elephant', 'danced', 'joyously.')\n",
            "('everyone', 'cheered.', 'together,')\n",
            "('frogs', 'recited', 'poetry.')\n",
            "('giant', 'soap', 'bubble,')\n",
            "('hat', 'cast', 'spells')\n",
            "('make', 'clouds', 'rain')\n",
            "('marshmallow', 'hat', 'cast')\n",
            "('melody,', 'attracting', 'jellybean')\n",
            "('purple', 'elephant', 'danced')\n",
            "('rain', 'lemonade.', 'nearby,')\n",
            "('rainbow-colored', 'cat', 'exclaimed,')\n",
            "('recited', 'poetry.', 'suddenly,')\n",
            "('soap', 'bubble,', 'leaving')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import webtext\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "\n",
        "file_path = '/content/NLP_trigram_example_shakespeare_excerpt.txt'\n",
        "\n",
        "words = [w.lower() for w in webtext.words(file_path)]\n",
        "\n",
        "bigram_collocation = BigramCollocationFinder.from_words(words)\n",
        "bigram_list = bigram_collocation.nbest(BigramAssocMeasures.likelihood_ratio, 20)\n",
        "\n",
        "print(\"Top 20 bigrams:\")\n",
        "for b in bigram_list:\n",
        "    print(b)\n",
        "\n",
        "print(\"\\n\\nAfter Stopwords removal:\\n\\n\")\n",
        "stopset = set(stopwords.words('english'))\n",
        "filter_stops = lambda w: len(w) < 3 or w in stopset\n",
        "\n",
        "bigram_collocation.apply_word_filter(filter_stops)\n",
        "bigram_list = bigram_collocation.nbest(BigramAssocMeasures.likelihood_ratio, 20)\n",
        "\n",
        "for b in bigram_list:\n",
        "    print(b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7u0q44Qch9P",
        "outputId": "391193f9-579b-40e1-c76f-8ef25b866079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 bigrams:\n",
            "('-', 'colored')\n",
            "('attracting', 'jellybean')\n",
            "('cast', 'spells')\n",
            "('cat', 'exclaimed')\n",
            "('clouds', 'rain')\n",
            "('colored', 'cat')\n",
            "('confetti', 'behind')\n",
            "('danced', 'joyously')\n",
            "('dragon', 'knitted')\n",
            "('elephant', 'danced')\n",
            "('enchanted', 'forest')\n",
            "('everyone', 'cheered')\n",
            "('floated', 'on')\n",
            "('friends', '!\"')\n",
            "('frogs', 'recited')\n",
            "('giant', 'soap')\n",
            "('giggling', 'at')\n",
            "('hat', 'cast')\n",
            "('in', 'this')\n",
            "('jellybean', 'birds')\n",
            "\n",
            "\n",
            "After Stopwords removal:\n",
            "\n",
            "\n",
            "('attracting', 'jellybean')\n",
            "('cast', 'spells')\n",
            "('cat', 'exclaimed')\n",
            "('clouds', 'rain')\n",
            "('colored', 'cat')\n",
            "('confetti', 'behind')\n",
            "('danced', 'joyously')\n",
            "('dragon', 'knitted')\n",
            "('elephant', 'danced')\n",
            "('enchanted', 'forest')\n",
            "('everyone', 'cheered')\n",
            "('frogs', 'recited')\n",
            "('giant', 'soap')\n",
            "('hat', 'cast')\n",
            "('jellybean', 'birds')\n",
            "('knitted', 'socks')\n",
            "('magical', 'land')\n",
            "('make', 'clouds')\n",
            "('marshmallow', 'hat')\n",
            "('purple', 'elephant')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Aug  8 09:58:16 2022\n",
        "@author: Niveditha\n",
        "\"\"\"\n",
        "\n",
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize, RegexpParser\n",
        "\n",
        "# Example text 6\n",
        "sample_text = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# Find all parts of speech in above sentence\n",
        "tagged = pos_tag(word_tokenize(sample_text))\n",
        "chunker = RegexpParser(\"\"\"\n",
        "\t\t\t\t\tNP: {<DT>?<JJ>*<NN>} #To extract Noun Phrases\n",
        "\t\t\t\t\tP: {<IN>}\t\t\t #To extract Prepositions\n",
        "\t\t\t\t\tV: {<V.*>}\t\t\t #To extract Verbs\n",
        "\t\t\t\t\tPP: {<p> <NP>}\t\t #To extract Prep. Phrases\n",
        "\t\t\t\t\tVP: {<V> <NP|PP>*}\t #To extract Verb Phrases\n",
        "\t\t\t\t\t\"\"\")\n",
        "\n",
        "# Print all parts of speech in above sentence\n",
        "output = chunker.parse(tagged)\n",
        "print(\"After Extracting\\n\", output)\n",
        "\n",
        "# Convert the output to a string and print it\n",
        "output_str = str(output)\n",
        "print(\"\\nParsed Syntax Tree:\\n\", output_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4cEWXpsd6MB",
        "outputId": "624269a5-6144-4c5f-9189-282dfe762f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Extracting\n",
            " (S\n",
            "  (NP The/DT quick/JJ brown/NN)\n",
            "  (NP fox/NN)\n",
            "  (VP (V jumps/VBZ))\n",
            "  (P over/IN)\n",
            "  (NP the/DT lazy/JJ dog/NN))\n",
            "\n",
            "Parsed Syntax Tree:\n",
            " (S\n",
            "  (NP The/DT quick/JJ brown/NN)\n",
            "  (NP fox/NN)\n",
            "  (VP (V jumps/VBZ))\n",
            "  (P over/IN)\n",
            "  (NP the/DT lazy/JJ dog/NN))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M1MZ1q9Wb5vm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}